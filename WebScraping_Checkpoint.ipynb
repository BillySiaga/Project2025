{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMo90k7sBb1GfXIBZPKbSHv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BillySiaga/Project2025/blob/main/WebScraping_Checkpoint.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Web Scraping Checkpoint"
      ],
      "metadata": {
        "id": "fVXtijnJeNna"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "OETFo0GJZEUJ",
        "outputId": "b7b2bd07-2604-42e5-809d-03981482200f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title: pandas (software)\n",
            "\n",
            "Text and Headings:\n",
            "History:\n",
            "  Developer Wes McKinney started working on Pandas in 2008 while at AQR Capital Management out of the need for a high performance, flexible tool to perform quantitative analysis on financial data. Before leaving AQR, he was able to convince management to allow him to open source the library.\n",
            "  Another AQR employee, Chang She, joined the effort in 2012 as the second major contributor to the library.\n",
            "  In 2015, Pandas signed on as a fiscally sponsored project of NumFOCUS, a 501(c)(3) nonprofit charity in the United States.[7]\n",
            "Data Model:\n",
            "  Pandas is built around data structures called Series and DataFrames. Data for these collections can be imported from various file formats such as comma-separated values, JSON, Parquet, SQL database tables or queries, and Microsoft Excel.[8]\n",
            "  A Series is a 1-dimensional data structure built on top of NumPy's array.[9]: 97  Unlike in NumPy, each data point has an associated label. The collection of these labels is called an index.[4]: 112  Series can be used arithmetically, as in the statement series_3 = series_1 + series_2: this will align data points with corresponding index values in series_1 and series_2, then add them together to produce new values in series_3.[4]: 114  A DataFrame is a 2-dimensional data structure of rows and columns, similar to a spreadsheet, and analogous to a Python dictionary mapping column names (keys) to Series (values), with each Series sharing an index.[4]: 115  DataFrames can be concatenated together or \"merged\" on columns or indices in a manner similar to joins in SQL.[4]: 177–182  Pandas implements a subset of relational algebra, and supports one-to-one, many-to-one, and many-to-many joins.[9]: 147–148  Pandas also supports the less common Panel and Panel4D, which are 3-dimensional and 4-dimension data structures respectively.[9]: 141\n",
            "  Users can transform or summarize data by applying arbitrary functions.[4]: 132  Since Pandas is built on top of NumPy, all NumPy functions work on Series and DataFrames as well.[9]: 115  Pandas also includes built-in operations for arithmetic, string manipulation, and summary statistics such as mean, median, and standard deviation.[4]: 139, 211  These built-in functions are designed to handle missing data, usually represented by the floating-point value NaN.[4]: 142–143\n",
            "  Subsets of data can be selected by column name, index, or Boolean expressions. For example, df[df['col1'] > 5] will return all rows in the DataFrame df for which the value of the column col1 exceeds 5.[4]: 126–128  Data can be grouped together by a column value, as in df['col1'].groupby(df['col2']), or by a function which is applied to the index. For example, df.groupby(lambda i: i % 2) groups data by whether the index is even.[4]: 253–259\n",
            "  Pandas includes support for time series, such as the ability to interpolate values [4]: 316–317  and filter using a range of timestamps (e.g. data['1/1/2023':'2/2/2023'] will return all dates between January 1st and February 2nd).[4]: 295  Pandas represents missing time series data using a special NaT (Not a Timestamp) object, instead of the NaN value it uses elsewhere.[4]: 292\n",
            "Indices:\n",
            "  By default, a Pandas index is a series of integers ascending from 0, similar to the indices of Python arrays. However, indices can use any NumPy data type, including floating point, timestamps, or strings.[4]: 112\n",
            "  Pandas' syntax for mapping index values to relevant data is the same syntax Python uses to map dictionary keys to values. For example, if s is a Series, s['a'] will return the data point at index a. Unlike dictionary keys, index values are not guaranteed to be unique. If a Series uses the index value a for multiple data points, then s['a'] will instead return a new Series containing all matching values.[4]: 136  A DataFrame's column names are stored and implemented identically to an index. As such, a DataFrame can be thought of as having two indices: one column-based and one row-based. Because column names are stored as an index, these are not required to be unique.[9]: 103–105\n",
            "  If data is a Series, then data['a'] returns all values with the index value of a. However, if data is a DataFrame, then data['a'] returns all values in the column(s) named a. To avoid this ambiguity, Pandas supports the syntax data.loc['a'] as an alternative way to filter using the index. Pandas also supports the syntax data.iloc[n], which always takes an integer n and returns the nth value, counting from 0. This allows a user to act as though the index is an array-like sequence of integers, regardless of how it is actually defined.[9]: 110–113\n",
            "  Pandas supports hierarchical indices with multiple values per data point. An index with this structure, called a \"MultiIndex\", allows a single DataFrame to represent multiple dimensions, similar to a pivot table in Microsoft Excel.[4]: 147–148  Each level of a MultiIndex can be given a unique name.[9]: 133  In practice, data with more than 2 dimensions is often represented using DataFrames with hierarchical indices, instead of the higher-dimension Panel and Panel4D data structures[9]: 128\n",
            "Criticisms:\n",
            "  Pandas has been criticized for its inefficiency. Pandas can require 5 to 10 times as much memory as the size of the underlying data, and the entire dataset must be loaded in RAM. The library does not optimize query plans or support parallel computing across multiple cores. Wes McKinney, the creator of Pandas, has recommended Apache Arrow as an alternative to address these performance concerns and other limitations.[10]\n",
            "See also:\n",
            "References:\n",
            "Further reading:\n",
            "\n",
            "Internal Links:\n",
            "https://en.wikipedia.org/wiki/Pandora_Archive#Software\n",
            "https://en.wikipedia.org/wiki/Panda\n",
            "https://en.wikipedia.org/wiki/Programmer\n",
            "https://en.wikipedia.org/wiki/Wes_McKinney\n",
            "https://en.wikipedia.org/wiki/Programmer\n",
            "https://en.wikipedia.org/wiki/Software_release_life_cycle\n",
            "https://en.wikipedia.org/wiki/Software_release_life_cycle#Beta\n",
            "https://en.wikipedia.org/wiki/Repository_(version_control)\n",
            "https://en.wikipedia.org/wiki/Python_(programming_language)\n",
            "https://en.wikipedia.org/wiki/Cython\n",
            "https://en.wikipedia.org/wiki/C_(programming_language)\n",
            "https://en.wikipedia.org/wiki/Operating_system\n",
            "https://en.wikipedia.org/wiki/Cross-platform\n",
            "https://en.wikipedia.org/wiki/Software_categories#Categorization_approaches\n",
            "https://en.wikipedia.org/wiki/List_of_numerical_analysis_software\n",
            "https://en.wikipedia.org/wiki/Software_license\n",
            "https://en.wikipedia.org/wiki/BSD-new\n",
            "https://en.wikipedia.org/wiki/Software_library\n",
            "https://en.wikipedia.org/wiki/Python_(programming_language)\n",
            "https://en.wikipedia.org/wiki/Data_analysis\n",
            "https://en.wikipedia.org/wiki/Data_structure\n",
            "https://en.wikipedia.org/wiki/Time_series\n",
            "https://en.wikipedia.org/wiki/Free_software\n",
            "https://en.wikipedia.org/wiki/3-clause_BSD_license\n",
            "https://en.wikipedia.org/wiki/Panel_data\n",
            "https://en.wikipedia.org/wiki/Econometrics\n",
            "https://en.wikipedia.org/wiki/Data_set\n",
            "https://en.wikipedia.org/wiki/Wes_McKinney\n",
            "https://en.wikipedia.org/wiki/AQR_Capital\n",
            "https://en.wikipedia.org/wiki/R_(programming_language)\n",
            "https://en.wikipedia.org/wiki/NumPy\n",
            "https://en.wikipedia.org/wiki/Wes_McKinney\n",
            "https://en.wikipedia.org/wiki/AQR_Capital\n",
            "https://en.wikipedia.org/wiki/Quantitative_analysis_(finance)\n",
            "https://en.wikipedia.org/wiki/Open_source\n",
            "https://en.wikipedia.org/wiki/501(c)(3)_organization\n",
            "https://en.wikipedia.org/wiki/Comma-separated_values\n",
            "https://en.wikipedia.org/wiki/JSON\n",
            "https://en.wikipedia.org/wiki/Apache_Parquet\n",
            "https://en.wikipedia.org/wiki/SQL\n",
            "https://en.wikipedia.org/wiki/Database\n",
            "https://en.wikipedia.org/wiki/Table_(database)\n",
            "https://en.wikipedia.org/wiki/Microsoft_Excel\n",
            "https://en.wikipedia.org/wiki/NumPy\n",
            "https://en.wikipedia.org/wiki/Spreadsheet\n",
            "https://en.wikipedia.org/wiki/Associative_array\n",
            "https://en.wikipedia.org/wiki/Join_(SQL)\n",
            "https://en.wikipedia.org/wiki/SQL\n",
            "https://en.wikipedia.org/wiki/Relational_algebra\n",
            "https://en.wikipedia.org/wiki/Function_(computer_programming)\n",
            "https://en.wikipedia.org/wiki/Arithmetic_mean\n",
            "https://en.wikipedia.org/wiki/Median\n",
            "https://en.wikipedia.org/wiki/Standard_deviation\n",
            "https://en.wikipedia.org/wiki/Floating-point_arithmetic\n",
            "https://en.wikipedia.org/wiki/NaN\n",
            "https://en.wikipedia.org/wiki/Boolean_expressions\n",
            "https://en.wikipedia.org/wiki/Time_series\n",
            "https://en.wikipedia.org/wiki/Interpolation\n",
            "https://en.wikipedia.org/wiki/Array_(data_type)\n",
            "https://en.wikipedia.org/wiki/Pivot_table\n",
            "https://en.wikipedia.org/wiki/Microsoft_Excel\n",
            "https://en.wikipedia.org/wiki/Random-access_memory\n",
            "https://en.wikipedia.org/wiki/Query_plan\n",
            "https://en.wikipedia.org/wiki/Parallel_computing\n",
            "https://en.wikipedia.org/wiki/Multi-core_processor\n",
            "https://en.wikipedia.org/wiki/Apache_Arrow\n",
            "https://en.wikipedia.org/wiki/Matplotlib\n",
            "https://en.wikipedia.org/wiki/NumPy\n",
            "https://en.wikipedia.org/wiki/Dask_(software)\n",
            "https://en.wikipedia.org/wiki/SciPy\n",
            "https://en.wikipedia.org/wiki/R_(programming_language)\n",
            "https://en.wikipedia.org/wiki/Scikit-learn\n",
            "https://en.wikipedia.org/wiki/List_of_numerical_analysis_software\n",
            "https://en.wikipedia.org/wiki/ISBN_(identifier)\n",
            "https://en.wikipedia.org/wiki/ISBN_(identifier)\n",
            "https://en.wikipedia.org/wiki/ISBN_(identifier)\n",
            "https://en.wikipedia.org/wiki/ISBN_(identifier)\n",
            "https://en.wikipedia.org/wiki/ISBN_(identifier)\n",
            "https://en.wikipedia.org/wiki/ISBN_(identifier)\n",
            "https://en.wikipedia.org/wiki/Python_(programming_language)\n",
            "https://en.wikipedia.org/wiki/NumPy\n",
            "https://en.wikipedia.org/wiki/SciPy\n",
            "https://en.wikipedia.org/wiki/Matplotlib\n",
            "https://en.wikipedia.org/wiki/Scikit-learn\n",
            "https://en.wikipedia.org/wiki/Scikit-image\n",
            "https://en.wikipedia.org/wiki/MayaVi\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "'''What You're Aiming For\n",
        "\n",
        "# The objective is to automate the extraction of HTML content, article titles, text, and internal links from Wikipedia pages into a consolidated function that accepts any Wikipedia URL for efficient data retrieval and processing.\n",
        "\n",
        "\n",
        "# Instructions\n",
        "\n",
        "# Create a Python script to automate data extraction from Wikipedia pages. The script will retrieve HTML content, extract article titles and text, collect internal links, and consolidate these tasks into one function that accepts a Wikipedia URL. This will be tested on a specific Wikipedia page to validate functionality.\n",
        "\n",
        "# 1) Write a function to Get and parse html content from a Wikipedia page\n",
        "\n",
        "# 2) Write a function to Extract article title\n",
        "\n",
        "# 3) Write a function to Extract article text for each paragraph with their respective\n",
        "\n",
        "# headings. Map those headings to their respective paragraphs in the dictionary.\n",
        "\n",
        "# 4) Write a function to collect every link that redirects to another Wikipedia page\n",
        "\n",
        "# 5) Wrap all the previous functions into a single function that takes as parameters a Wikipedia link\n",
        "\n",
        "# 6) Test the last function on a Wikipedia page of your choice'''\n",
        "#\n",
        "#Import requests\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "link = \"https://en.wikipedia.org/wiki/Pandas_(software)\"\n",
        "response = requests.get(link)\n",
        "response.status_code\n",
        "page_content = response.content\n",
        "#\n",
        "#parsing the link\n",
        "soup = BeautifulSoup(page_content, 'html.parser')\n",
        "\n",
        "# Extract title\n",
        "title = soup.find('h1', {'id': 'firstHeading'}).text\n",
        "print(f\"Title: {title}\\n\")\n",
        "\n",
        "# Extract text and headings\n",
        "content = soup.find('div', {'id': 'bodyContent'})\n",
        "paragraphs = content.find_all(['h2', 'h3', 'p'])\n",
        "\n",
        "article = {}\n",
        "current_heading = None\n",
        "\n",
        "for tag in paragraphs:\n",
        "  if tag.name in ['h2', 'h3']:\n",
        "    current_heading = tag.text.strip()\n",
        "    article[current_heading] = []\n",
        "  elif tag.name == 'p':\n",
        "      if current_heading:\n",
        "        article[current_heading].append(tag.text.strip())\n",
        "\n",
        "print(\"Text and Headings:\")\n",
        "for heading, paragraphs in article.items():\n",
        "  print(f\"{heading}:\")\n",
        "  for paragraph in paragraphs:\n",
        "    print(f\"  {paragraph}\")\n",
        "\n",
        "# Extract internal links\n",
        "links = content.find_all('a', href=True)\n",
        "internal_links = [f\"https://en.wikipedia.org{link['href']}\" for link in links if link['href'].startswith('/wiki/') and not ':' in link['href']]\n",
        "\n",
        "print(\"\\nInternal Links:\")\n",
        "for link in internal_links:\n",
        "  print(link)\n"
      ]
    }
  ]
}